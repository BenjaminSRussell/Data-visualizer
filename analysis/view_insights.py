"""
View Analysis Insights - Interactive Report Viewer

Purpose: Display the most important and interesting insights from the analysis
"""

import json
import sys
from pathlib import Path
from collections import Counter
from typing import Dict


def load_results(results_dir: str = 'analysis/results'):
    """Load analysis results."""
    results_path = Path(results_dir)

    try:
        with open(results_path / 'analysis_results.json', 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"Error: Results not found in {results_dir}")
        print("Run the master pipeline first:")
        print("  python3 analysis/pipeline/master_pipeline.py Site.jsonl analysis/results")
        sys.exit(1)


def print_header(title: str):
    """Print section header."""
    print("\n" + "="*80)
    print(title.center(80))
    print("="*80)


def print_section(title: str):
    """Print subsection header."""
    print(f"\n{title}")
    print("-" * 80)


def view_overview(results: Dict):
    """Display overview metrics."""
    print_header("ğŸ“Š ANALYSIS OVERVIEW")

    meta = results.get('metadata', {})
    insights = results.get('insights', {})

    print(f"\nğŸ“ Dataset: {meta.get('input_file', 'N/A')}")
    print(f"ğŸ“… Analyzed: {meta.get('analysis_timestamp', 'N/A')[:19]}")
    print(f"ğŸ”— Total URLs: {meta.get('total_urls', 0):,}")
    print(f"âš¡ Analysis Time: {meta.get('total_execution_time', 0):.2f}s")

    if 'scores' in insights:
        print("\nğŸ¯ Overall Scores:")
        for score_name, score_value in insights['scores'].items():
            emoji = "ğŸŸ¢" if score_value >= 80 else "ğŸŸ¡" if score_value >= 60 else "ğŸ”´"
            print(f"  {emoji} {score_name.replace('_', ' ').title()}: {score_value:.1f}/100")


def view_statistical_insights(results: Dict):
    """Display statistical insights."""
    print_header("ğŸ“ˆ STATISTICAL ANALYSIS")

    stats = results.get('statistical', {})

    if 'summary_stats' in stats:
        print_section("Basic Statistics")
        summary = stats['summary_stats']

        print(f"  Depth:")
        print(f"    â€¢ Average: {summary.get('depth_mean', 0):.2f}")
        print(f"    â€¢ Range: {summary.get('depth_min', 0):.0f} - {summary.get('depth_max', 0):.0f}")
        print(f"    â€¢ Median: {summary.get('depth_median', 0):.2f}")

        print(f"\n  Path Length:")
        print(f"    â€¢ Average: {summary.get('path_length_mean', 0):.2f} chars")
        print(f"    â€¢ Range: {summary.get('path_length_min', 0):.0f} - {summary.get('path_length_max', 0):.0f}")

        print(f"\n  Outbound Links:")
        print(f"    â€¢ Average per page: {summary.get('outbound_links_mean', 0):.2f}")
        print(f"    â€¢ Maximum: {summary.get('outbound_links_max', 0):.0f}")

    if 'url_health' in stats:
        print_section("URL Health Assessment")
        health = stats['url_health']

        grade = health.get('health_grade', 'N/A')
        grade_emoji = {"A": "ğŸŒŸ", "B": "â­", "C": "âœ¨", "D": "ğŸ’«", "F": "âŒ"}.get(grade, "â“")

        print(f"  {grade_emoji} Overall Health: {health.get('overall_health', 0):.1f}/100 (Grade: {grade})")
        print(f"  â€¢ URL Length Optimization: {health.get('url_length_score', 0):.1f}%")
        print(f"  â€¢ Depth Optimization: {health.get('depth_score', 0):.1f}%")
        print(f"  â€¢ Fragment Health: {health.get('fragment_score', 0):.1f}%")

    if 'correlations' in stats:
        print_section("Interesting Correlations")
        for name, corr in stats['correlations'].items():
            if corr.get('significant'):
                emoji = "ğŸ“ˆ" if corr['correlation'] > 0 else "ğŸ“‰"
                print(f"  {emoji} {name.replace('_', ' ').title()}")
                print(f"     {corr['interpretation']}")
                print(f"     (r={corr['correlation']:.3f}, p={corr['p_value']:.4f})")


def view_semantic_insights(results: Dict):
    """Display semantic analysis insights."""
    print_header("ğŸ”¤ SEMANTIC ANALYSIS")

    semantic = results.get('semantic_path', {})

    if 'vocabulary' in semantic:
        print_section("Vocabulary Analysis")
        vocab = semantic['vocabulary']

        print(f"  ğŸ“š Total Tokens: {vocab.get('total_tokens', 0):,}")
        print(f"  ğŸ“– Unique Tokens: {vocab.get('unique_tokens', 0):,}")
        print(f"  ğŸ¨ Diversity: {vocab.get('vocabulary_diversity', 'N/A').upper()}")

        if 'top_tokens' in vocab:
            print(f"\n  ğŸ” Top 15 Keywords:")
            top_tokens = list(vocab['top_tokens'].items())[:15]
            for i, (token, count) in enumerate(top_tokens, 1):
                bar = "â–ˆ" * min(int(count / top_tokens[0][1] * 20), 20)
                print(f"    {i:2d}. {token:20s} {bar} {count:4d}")

    if 'semantic_categories' in semantic:
        print_section("Content Categories")
        categories = semantic['semantic_categories']

        if 'dominant_category' in categories:
            dom = categories['dominant_category']
            print(f"  ğŸ¯ Dominant: {dom.get('name', 'Unknown').upper()} ({dom.get('count', 0)} pages)")

        print(f"\n  ğŸ“Š Distribution:")
        cat_items = [(k, v) for k, v in categories.items() if k != 'dominant_category']
        cat_items.sort(key=lambda x: x[1].get('count', 0) if isinstance(x[1], dict) else 0, reverse=True)

        for cat, data in cat_items[:10]:
            if isinstance(data, dict):
                count = data.get('count', 0)
                pct = data.get('percentage', 0)
                print(f"    â€¢ {cat:20s}: {count:4d} ({pct:5.1f}%)")

    if 'content_type_prediction' in semantic:
        print_section("Predicted Content Types")
        content_types = semantic['content_type_prediction']

        sorted_types = sorted(content_types.items(), key=lambda x: x[1]['count'], reverse=True)

        for ctype, data in sorted_types[:8]:
            count = data['count']
            pct = data['percentage']
            bar = "â–“" * min(int(pct / 2), 40)
            print(f"  {ctype:25s} {bar} {pct:5.1f}% ({count:,})")


def view_network_insights(results: Dict):
    """Display network analysis insights."""
    print_header("ğŸŒ NETWORK ANALYSIS")

    network = results.get('network', {})

    if 'network_metrics' in network:
        print_section("Network Metrics")
        metrics = network['network_metrics']

        print(f"  ğŸ”— Nodes: {metrics.get('nodes', 0):,}")
        print(f"  â¡ï¸  Edges: {metrics.get('edges', 0):,}")
        print(f"  ğŸ•¸ï¸  Density: {metrics.get('density', 0):.6f}")
        print(f"  ğŸ“Š Average Degree: {metrics.get('average_degree', 0):.2f}")
        print(f"  ğŸ”„ Reciprocity: {metrics.get('reciprocity', 0):.4f}")

    if 'centrality' in network:
        print_section("Most Central Pages")
        centrality = network['centrality']

        if centrality.get('top_by_degree'):
            print(f"\n  ğŸŒŸ Top 5 by Total Connections:")
            for i, item in enumerate(centrality['top_by_degree'][:5], 1):
                print(f"    {i}. [{item['degree']:3d} connections] {item['url'][:70]}")

        if centrality.get('top_by_in_degree'):
            print(f"\n  â¬‡ï¸  Top 5 by Incoming Links (Authority):")
            for i, item in enumerate(centrality['top_by_in_degree'][:5], 1):
                print(f"    {i}. [{item['in_degree']:3d} incoming] {item['url'][:70]}")

    if 'link_patterns' in network:
        print_section("Link Patterns")
        patterns = network['link_patterns']

        print(f"  ğŸ”— Self Links: {patterns.get('self_links', 0):,}")
        print(f"  ğŸŒ External Links: {patterns.get('external_links', 0):,}")
        print(f"  ğŸ‘¥ Sibling Links: {patterns.get('sibling_links', 0):,}")

    if 'community_detection' in network:
        print_section("Communities")
        communities = network['community_detection']

        print(f"  ğŸ“¦ Total Communities: {communities.get('total_communities', 0)}")

        if communities.get('top_communities'):
            print(f"\n  ğŸ” Largest Communities:")
            for i, comm in enumerate(communities['top_communities'][:5], 1):
                print(f"    {i}. {comm['community']:30s}: {comm['size']:4d} pages ({comm['percentage']:5.1f}%)")


def view_pathway_insights(results: Dict):
    """Display pathway analysis insights."""
    print_header("ğŸ—ºï¸  PATHWAY ANALYSIS")

    pathway = results.get('pathway', {})

    if 'architecture' in pathway:
        print_section("Site Architecture")
        arch = pathway['architecture']

        arch_type = arch.get('architecture_type', 'unknown').upper()
        arch_emoji = {
            'FLAT': 'ğŸ“‹',
            'DEEP': 'ğŸ”ï¸',
            'WIDE': 'ğŸŒŠ',
            'BALANCED': 'âš–ï¸'
        }.get(arch_type, 'â“')

        print(f"  {arch_emoji} Type: {arch_type}")
        print(f"  ğŸ“ Max Depth: {arch.get('max_depth', 0)} levels")
        print(f"  ğŸ‘¥ Avg Children per Parent: {arch.get('avg_children_per_parent', 0):.2f}")
        print(f"  ğŸ”— Total Relationships: {arch.get('total_relationships', 0):,}")
        print(f"  ğŸ‘» Orphan Pages: {arch.get('orphan_pages', 0)}")

    if 'entry_points' in pathway:
        print_section("Entry Points")
        entry = pathway['entry_points']

        print(f"  ğŸšª Total Entry Points: {entry.get('count', 0)}")

        if entry.get('top_entry_points'):
            print(f"\n  ğŸ” Top 5 Entry Points:")
            for i, ep in enumerate(entry['top_entry_points'][:5], 1):
                print(f"    {i}. [Depth {ep['depth']}, {ep['children_count']} children] {ep['url'][:60]}")

    if 'navigation_hubs' in pathway:
        print_section("Navigation Hubs")
        hubs = pathway['navigation_hubs']

        print(f"  ğŸ¯ Total Hubs: {hubs.get('count', 0)}")

        if hubs.get('top_hubs'):
            print(f"\n  ğŸ” Top 5 Hubs:")
            for i, hub in enumerate(hubs['top_hubs'][:5], 1):
                print(f"    {i}. [{hub['total_connectivity']} connections] {hub['url'][:60]}")

    if 'dead_ends' in pathway:
        print_section("Dead Ends")
        dead = pathway['dead_ends']

        emoji = "ğŸ”´" if dead.get('percentage', 0) > 30 else "ğŸŸ¡" if dead.get('percentage', 0) > 15 else "ğŸŸ¢"
        print(f"  {emoji} Dead-End Pages: {dead.get('count', 0):,} ({dead.get('percentage', 0):.1f}%)")


def view_alerts_recommendations(results: Dict):
    """Display alerts and recommendations."""
    print_header("âš ï¸  ALERTS & RECOMMENDATIONS")

    insights = results.get('insights', {})

    if insights.get('alerts'):
        print_section("âš ï¸  Alerts")
        for i, alert in enumerate(insights['alerts'], 1):
            print(f"  {i}. {alert}")

    if insights.get('recommendations'):
        print_section("ğŸ’¡ Recommendations")
        for i, rec in enumerate(insights['recommendations'], 1):
            print(f"  {i}. {rec}")


def main():
    """Main function."""

    results_dir = sys.argv[1] if len(sys.argv) > 1 else 'analysis/results'

    results = load_results(results_dir)

    print("\n" + "â–ˆ"*80)
    print("  ğŸ” URL ANALYSIS INSIGHTS VIEWER".center(80))
    print("â–ˆ"*80)

    view_overview(results)
    view_statistical_insights(results)
    view_semantic_insights(results)
    view_network_insights(results)
    view_pathway_insights(results)
    view_alerts_recommendations(results)

    print("\n" + "="*80)
    print("ğŸ“ Full results available in: " + results_dir)
    print("="*80 + "\n")


if __name__ == '__main__':
    main()
